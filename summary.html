<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-01-27 Thu 10:19 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Bachelor Thesis Dimensionality Reduction</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Massimiliano Falzari (s3459101)" />
<meta name="keywords" content="autoencoder,dimensionality reduction,latent space" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/bigblow_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/bigblow_theme/css/bigblow.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/bigblow_theme/css/hideshow.css"/>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/bigblow_theme/js/jquery-1.11.0.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/bigblow_theme/js/jquery-ui-1.10.2.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/bigblow_theme/js/jquery.localscroll-min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/bigblow_theme/js/jquery.scrollTo-1.4.3.1-min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/bigblow_theme/js/jquery.zclip.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/bigblow_theme/js/bigblow.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/bigblow_theme/js/hideshow.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Bachelor Thesis Dimensionality Reduction</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgbadb62f">1. Overview</a>
<ul>
<li><a href="#org8acd303">1.1. Project scope</a></li>
<li><a href="#org916e09c">1.2. Index:</a>
<ul>
<li><a href="#org4894a3d">1.2.1. Lines of Thoughts</a></li>
<li><a href="#org66649da">1.2.2. Papers</a></li>
<li><a href="#orge17ba4c">1.2.3. Autoencoders</a></li>
<li><a href="#org1089e99">1.2.4. Ideas for Hyperparameters</a></li>
<li><a href="#org91a9de7">1.2.5. Code</a></li>
<li><a href="#orgd6e9805">1.2.6. Todos</a></li>
<li><a href="#org9ba3a48">1.2.7. Presentations</a></li>
<li><a href="#orgad0ffef">1.2.8. Contacts</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org1dbf4cb">2. Lines of Thoughts</a>
<ul>
<li><a href="#org73837eb">2.1. Autoencoder</a></li>
<li><a href="#org9ef2ab0">2.2. <span class="todo TODO">TODO</span> PCA</a>
<ul>
<li><a href="#org7623a56">2.2.1. Assumptions</a></li>
</ul>
</li>
<li><a href="#orgef43839">2.3. <span class="todo TODO">TODO</span> LDA</a></li>
<li><a href="#org4397639">2.4. <span class="todo TODO">TODO</span> LLE</a></li>
<li><a href="#orgd50b4e2">2.5. <span class="todo TODO">TODO</span> Isomap</a></li>
</ul>
</li>
<li><a href="#org52d3037">3. Ideas for Hyperparameters</a>
<ul>
<li><a href="#org80f5782">3.1. Number of neurons per layer</a></li>
</ul>
</li>
<li><a href="#orgddeb39b">4. ML Pipeline</a></li>
<li><a href="#orgd57fb50">5. Autoencoders</a>
<ul>
<li><a href="#org45249a9">5.1. <span class="done DONE">DONE</span> Vanilla</a></li>
<li><a href="#org829436b">5.2. <span class="done DONE">DONE</span> VAE</a></li>
<li><a href="#org4ca9107">5.3. <span class="done DONE">DONE</span> AVB</a></li>
<li><a href="#orga38f753">5.4. <span class="todo HOLD">HOLD</span> B-VAE</a></li>
<li><a href="#org7012fcf">5.5. <span class="todo HOLD">HOLD</span> InfoVae</a></li>
</ul>
</li>
<li><a href="#orgb3b3a2c">6. Papers</a>
<ul>
<li><a href="#org4394502">6.1. <span class="todo INPROGRESS">INPROGRESS</span> Dimensionality reduction</a>
<ul>
<li><a href="#org5f4687f">6.1.1. Common knowledge resources</a></li>
<li><a href="#org96d23d9">6.1.2. <span class="todo INPROGRESS">INPROGRESS</span> Autoencoders:</a></li>
<li><a href="#org81c9f4c">6.1.3. <span class="todo INPROGRESS">INPROGRESS</span> Dimensionality reduction:</a></li>
<li><a href="#orgaaa0903">6.1.4. <span class="todo INPROGRESS">INPROGRESS</span> AE + RL:</a></li>
</ul>
</li>
<li><a href="#org9d1f395">6.2. Old ideas</a>
<ul>
<li><a href="#org960eb89">6.2.1. <span class="done DONE">DONE</span> Deep reinforcement learning for modeling human locomotion control in neuromechanical simulation </a></li>
</ul>
</li>
<li><a href="#org5f960be">6.3. Old work</a>
<ul>
<li><a href="#org67505c2">6.3.1. Level ground walking for  healthy and transfemoral amputee models. Deep reinforcement learning with phasic policy gradient optimization </a></li>
<li><a href="#org27677b0">6.3.2. Deep reinforcement learning for physics-based musculoskeletal model of a transfemoral amputee with a prothesis walking on uneven terrain </a></li>
<li><a href="#org6d9ceb2">6.3.3. Deep reinforcement learning for physics-based musculoskeletal simulations of healthy subjects and transfemoral protheses' users during normal walking </a></li>
<li><a href="#org1b75d79">6.3.4. Learning to walk: Phasic Policy Gradient for healthy and impaired musculoskeletal models </a></li>
<li><a href="#orgb2a2119">6.3.5. Evaluating Deep Reinforcement Learning Algorithms for Physics-Based Musculoskeletal Transfemoral Model with a Prosthetic Leg Performing Ground-Level Walking </a></li>
<li><a href="#org316b561">6.3.6. Deep Reinforcement Learning for Physics-based Musculoskeletal Simulations of Transfemoral Prosthesis' Users during the Transition between Normal Walking and Stairs Ascending </a></li>
<li><a href="#org5b303d6">6.3.7. Testing For Generality Of A Proximal Policy Optimiser For Advanced Human Locomotion Beyond Walking </a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orge70ab74">7. Presentations</a>
<ul>
<li><a href="#orgdb24c8e">7.1. First one</a></li>
</ul>
</li>
<li><a href="#org8f3c7f9">8. <span class="todo INPROGRESS">INPROGRESS</span> Code</a>
<ul>
<li><a href="#org8244f44">8.1. REPOS</a></li>
</ul>
</li>
<li><a href="#org9b94fb9">9. Contacts</a>
<ul>
<li><a href="#org5069c0c">9.1. Massimiliano Falzari</a></li>
<li><a href="#orge9569ff">9.2. Professor</a></li>
<li><a href="#org1ecc71a">9.3. Other Students</a></li>
</ul>
</li>
<li><a href="#orgeef5044">10. Todos</a>
<ul>
<li><a href="#org9a53233">10.1. Code</a>
<ul>
<li><a href="#org7469f4b">10.1.1. <span class="done DONE">DONE</span> Vanilla Autoencoder</a></li>
<li><a href="#orge1af2d1">10.1.2. <span class="done DONE">DONE</span> VAE</a></li>
<li><a href="#org27b3771">10.1.3. <span class="done DONE">DONE</span> AVB</a></li>
<li><a href="#org6723f19">10.1.4. <span class="done DONE">DONE</span> logging</a></li>
<li><a href="#org399b7a5">10.1.5. <span class="done DONE">DONE</span> tensorboard</a></li>
<li><a href="#orgecb696d">10.1.6. <span class="done DONE">DONE</span> data loader</a></li>
<li><a href="#org54e2b72">10.1.7. <span class="done DONE">DONE</span> cross validation</a></li>
<li><a href="#orgfd48abd">10.1.8. <span class="done DONE">DONE</span> parse config</a></li>
<li><a href="#orge81d7bf">10.1.9. <span class="done DONE">DONE</span> writer</a></li>
<li><a href="#org4a856d7">10.1.10. <span class="done DONE">DONE</span> validate with different loss</a></li>
<li><a href="#org91e78d9">10.1.11. <span class="done DONE">DONE</span> Create config parser module</a></li>
<li><a href="#org09b18d1">10.1.12. <span class="todo HOLD">HOLD</span> Dict -&gt; nametuple</a></li>
<li><a href="#org1a911ce">10.1.13. <span class="todo INPROGRESS">INPROGRESS</span> Graph module</a></li>
<li><a href="#orgb3930a6">10.1.14. <span class="todo HOLD">HOLD</span> Collect Data from simulation</a></li>
</ul>
</li>
<li><a href="#org1736ec1">10.2. Paper</a>
<ul>
<li><a href="#org36b5f03">10.2.1. <span class="todo INPROGRESS">INPROGRESS</span> Review all papers</a></li>
<li><a href="#orgd02bf28">10.2.2. <span class="todo HOLD">HOLD</span> Why we use autoencoders</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-orgbadb62f" class="outline-2">
<h2 id="orgbadb62f"><span class="section-number-2">1</span> Overview</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org8acd303" class="outline-3">
<h3 id="org8acd303"><span class="section-number-3">1.1</span> Project scope</h3>
<div class="outline-text-3" id="text-1-1">
<p>
The project aim to build an autoencoder for dimensionality
reduction. In particular, this will be used to hopefully enhance the
performance of a DRL algorithm for opensim-rl simulation.
In this project different type of Autoencoders will be tested.
</p>
</div>
</div>

<div id="outline-container-org916e09c" class="outline-3">
<h3 id="org916e09c"><span class="section-number-3">1.2</span> Index:</h3>
<div class="outline-text-3" id="text-1-2">
</div>
<div id="outline-container-org4894a3d" class="outline-4">
<h4 id="org4894a3d"><span class="section-number-4">1.2.1</span> <a href="#org1dbf4cb">Lines of Thoughts</a></h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
A kinda of overview on what the thesis is about (e.i. Autoencoders and
dimensionality reduction)
</p>
</div>
</div>
<div id="outline-container-org66649da" class="outline-4">
<h4 id="org66649da"><span class="section-number-4">1.2.2</span> <a href="#orgb3b3a2c">Papers</a></h4>
<div class="outline-text-4" id="text-1-2-2">
<p>
A list of all the background literature found. For each of paper there
is a short description of the aims and  the results.
</p>
</div>
</div>
<div id="outline-container-orge17ba4c" class="outline-4">
<h4 id="orge17ba4c"><span class="section-number-4">1.2.3</span> <a href="#orgd57fb50">Autoencoders</a></h4>
<div class="outline-text-4" id="text-1-2-3">
<p>
Contains a list of implemented and not autoencoders
</p>
</div>
</div>
<div id="outline-container-org1089e99" class="outline-4">
<h4 id="org1089e99"><span class="section-number-4">1.2.4</span> <a href="#org52d3037">Ideas for Hyperparameters</a></h4>
<div class="outline-text-4" id="text-1-2-4">
<p>
Contains some ideas for the hyperparameters fitting and some maybe
clever ideas
</p>
</div>
</div>
<div id="outline-container-org91a9de7" class="outline-4">
<h4 id="org91a9de7"><span class="section-number-4">1.2.5</span> <a href="#org8f3c7f9">Code</a></h4>
<div class="outline-text-4" id="text-1-2-5">
<p>
Contains the git repo and the link for the code documentation
</p>
</div>
</div>
<div id="outline-container-orgd6e9805" class="outline-4">
<h4 id="orgd6e9805"><span class="section-number-4">1.2.6</span> <a href="#orgeef5044">Todos</a></h4>
<div class="outline-text-4" id="text-1-2-6">
<p>
Contains a list of different type of Todo
</p>
</div>
</div>
<div id="outline-container-org9ba3a48" class="outline-4">
<h4 id="org9ba3a48"><span class="section-number-4">1.2.7</span> <a href="#orge70ab74">Presentations</a></h4>
<div class="outline-text-4" id="text-1-2-7">
<p>
Contains all the presentations done or in progress
</p>
</div>
</div>
<div id="outline-container-orgad0ffef" class="outline-4">
<h4 id="orgad0ffef"><span class="section-number-4">1.2.8</span> <a href="#org9b94fb9">Contacts</a></h4>
<div class="outline-text-4" id="text-1-2-8">
<p>
Self explanatory
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org1dbf4cb" class="outline-2">
<h2 id="org1dbf4cb"><span class="section-number-2">2</span> Lines of Thoughts</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-org73837eb" class="outline-3">
<h3 id="org73837eb"><span class="section-number-3">2.1</span> Autoencoder</h3>
<div class="outline-text-3" id="text-2-1">
<p>
An Autoencoder is a special network architecture which approximate two
different function <b>encode</b> and <b>decode</b> such as:
\[decode(encode(\hat{X})) = \hat{X}\]
</p>
<div class="info" id="orgbeb5c17">
<p>
<b>Note</b>  most of the the time is not an = but an &asymp;
</p>

</div>

<p>
The network is therefore composed by two different sub networks. An
Encoder which can be defined as:
\[encode \rightarrow \mathbb{R}^n \times \mathbb{R}^m \]
And a Decoder which can be defined as:
\[decode \rightarrow \mathbb{R}^m \times \mathbb{R}^n \]
</p>

<p>
There two constraint to this two function. The first one is that
<b>decode</b> must be approximately the inverse of the <b>encode</b><sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup>. The second one is that
\[ m << n \]
</p>
<div class="info" id="orgf5d0ea0">
<p>
<b>NOTE</b> when the second constraint is sudisfacted, the autoencoder is
 cosidered an undercomplete autoencoder. However, every time we will
 use the autoencoder word we will refer to undercomplete autoencoder.
</p>

</div>
<p>
The second constraint is an architectural one, meanwhile the first one
is a functional constraint which will be achived after the network is
trained.
</p>

<p>
The error function is therefore a reconstruction error or distance
measure between the input and outuput.
</p>

<p>
The layer between the Encoder and the Decoder express what is usually
knonw as <b>Latent space</b> which dimensionality is \(\mathbb{R}^m\).
</p>

<p>
We will from now on refer to the <b>Latent space</b> as \(\hat{z}\).
For clarity we can rewrite the above formulas as:
\[encode(\hat{X}) = \hat{z}\]
\[decode(\hat{z}) \approx \hat{X}\]
</p>
<p width="600em">
<img src="resources/autoencoder.png" alt="autoencoder.png" width="600em" />
As Wang stated <sup><a id="fnr.2" class="footref" href="#fn.2">2</a></sup>
</p>
<p class="verse">
Auto-encoder can be seen as a way to transform representation.<br />
</p>
</div>
</div>

<div id="outline-container-org9ef2ab0" class="outline-3">
<h3 id="org9ef2ab0"><span class="section-number-3">2.2</span> <span class="todo TODO">TODO</span> PCA</h3>
<div class="outline-text-3" id="text-2-2">
<p>
find a linear subspace with lower dimension than the initial dataset
while trying to maintain most of the variability
</p>
</div>
<div id="outline-container-org7623a56" class="outline-4">
<h4 id="org7623a56"><span class="section-number-4">2.2.1</span> Assumptions</h4>
<div class="outline-text-4" id="text-2-2-1">
<ul class="org-ul">
<li>Linear dimensions</li>
<li>approximately normally distributed data</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgef43839" class="outline-3">
<h3 id="orgef43839"><span class="section-number-3">2.3</span> <span class="todo TODO">TODO</span> LDA</h3>
<div class="outline-text-3" id="text-2-3">
<p>
linear approach
</p>
</div>
</div>
<div id="outline-container-org4397639" class="outline-3">
<h3 id="org4397639"><span class="section-number-3">2.4</span> <span class="todo TODO">TODO</span> LLE</h3>
<div class="outline-text-3" id="text-2-4">
<p>
non-linear approach
</p>
</div>
</div>
<div id="outline-container-orgd50b4e2" class="outline-3">
<h3 id="orgd50b4e2"><span class="section-number-3">2.5</span> <span class="todo TODO">TODO</span> Isomap</h3>
<div class="outline-text-3" id="text-2-5">
<p>
non linear generalization of classical multidimensional scaling
</p>
</div>
</div>
</div>

<div id="outline-container-org52d3037" class="outline-2">
<h2 id="org52d3037"><span class="section-number-2">3</span> Ideas for Hyperparameters</h2>
<div class="outline-text-2" id="text-3">
<p>
Since we will have to fit quite a lot of hyperparameters we tried to come
up with some cleaver ideas to remove some  of these
hyperparameters.
</p>
</div>

<div id="outline-container-org80f5782" class="outline-3">
<h3 id="org80f5782"><span class="section-number-3">3.1</span> Number of neurons per layer</h3>
<div class="outline-text-3" id="text-3-1">
<p>
The first hyperparameters we would like to remove is the number of
neurons per layer. Since we are doing an autoencoder and therefore
we are trying to find a compression function <b>f</b> we can assume that
the number of neurons per layer is defined by some kind of function
<b>h</b> that given the number of layers <b>N</b>, the numeber of dimension of
the input <b>I</b> and the final number of dimension of the latent space
<b>Z</b> returns the number of neurons for a specific layer.
This function can be either linear or non-linear. The first
intuition is that if <b>h</b> is linear it should be somewhat easier to
learn a good compression function <b>f</b>. However, until now, we do not
have any mathematical backgroud for this intuition! We need to do
more research!
</p>

<p>
The first possible implementation of this function is defined as
follows: (<b>n</b> is the index of the layer for which we are trying to
find the number of neurons)
</p>

<p>
\[n_1 = I\]
\[n_N = Z\]
\[n_i = n_{i+1}*\lambda\]
From these equations we can find out the equation which define the
value of &lambda; quite intuitevely.
\[ \lambda = \sqrt[N-1]{\frac{I}{Z}} \]
Now we can derive the number of layers given the
number of neurons for the first and last layer
\[ n_i = n_N * \prod_{x=1}^{N-i}  \lambda \]
\[ n_i= n_N * \lambda^{N-1}\]
Substitute &lambda; with the prievious found equation.
\[ n_i = n_N *  \left(\sqrt[N-1]{\frac{I}{Z}}\right)^ {N-i} \]
\[ n_i = n_N * \left(\frac{I}{Z}\right)^{\frac{N-i}{N-1}} \]
\[ n_i = Z * \left(\frac{I}{Z}\right)^{\frac{N-i}{N-1}} \]
</p>
</div>
</div>
</div>

<div id="outline-container-orgddeb39b" class="outline-2">
<h2 id="orgddeb39b"><span class="section-number-2">4</span> ML Pipeline</h2>
<div class="outline-text-2" id="text-4">
<iframe src="resources/ML-pipeline.pdf" width="100%" style="height:50em" align="center"> </iframe>
</div>
</div>
<div id="outline-container-orgd57fb50" class="outline-2">
<h2 id="orgd57fb50"><span class="section-number-2">5</span> Autoencoders</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-org45249a9" class="outline-3">
<h3 id="org45249a9"><span class="section-number-3">5.1</span> <span class="done DONE">DONE</span> Vanilla</h3>
<div class="outline-text-3" id="text-5-1">
<p>
The vanilla autoencoder is the classical one. Composed by an
encoder and a decoder without any kind of constriction.
</p>
</div>
</div>
<div id="outline-container-org829436b" class="outline-3">
<h3 id="org829436b"><span class="section-number-3">5.2</span> <span class="done DONE">DONE</span> VAE</h3>
<div class="outline-text-3" id="text-5-2">
<p>
The Variational autoencoder is a modified version of a vanilla AE
which forces the distribution of the latent space to be a
gaussian.
</p>
</div>
</div>
<div id="outline-container-org4ca9107" class="outline-3">
<h3 id="org4ca9107"><span class="section-number-3">5.3</span> <span class="done DONE">DONE</span> AVB</h3>
<div class="outline-text-3" id="text-5-3">
<p>
Adversarial Variational Bayes is a relatively new ideas which
exploits some Bayesian concept to force a particular latent space
distribution. All is done in an adversarial environment.
</p>
</div>
</div>
<div id="outline-container-orga38f753" class="outline-3">
<h3 id="orga38f753"><span class="section-number-3">5.4</span> <span class="todo HOLD">HOLD</span> B-VAE</h3>
</div>

<div id="outline-container-org7012fcf" class="outline-3">
<h3 id="org7012fcf"><span class="section-number-3">5.5</span> <span class="todo HOLD">HOLD</span> InfoVae</h3>
</div>
</div>

<div id="outline-container-orgb3b3a2c" class="outline-2">
<h2 id="orgb3b3a2c"><span class="section-number-2">6</span> Papers</h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-org4394502" class="outline-3">
<h3 id="org4394502"><span class="section-number-3">6.1</span> <span class="todo INPROGRESS">INPROGRESS</span> Dimensionality reduction</h3>
<div class="outline-text-3" id="text-6-1">
</div>
<div id="outline-container-org5f4687f" class="outline-4">
<h4 id="org5f4687f"><span class="section-number-4">6.1.1</span> Common knowledge resources</h4>
<div class="outline-text-4" id="text-6-1-1">
<ul class="org-ul">
<li><a href="https://www.analyticsvidhya.com/blog/2021/06/dimensionality-reduction-using-autoencoders-in-python/">autoencoder dim red python</a></li>
<li><a href="https://towardsdatascience.com/11-dimensionality-reduction-techniques-you-should-know-in-2021-dcb9500d388b">dimredtechniques</a></li>
<li><a href="https://iq.opengenus.org/applications-of-autoencoders/">applications autoencoders</a></li>
<li><a href="https://towardsdatascience.com/how-to-mitigate-overfitting-with-dimensionality-reduction-555b755b3d66">reduce overfitting dim red</a></li>
</ul>
</div>
</div>

<div id="outline-container-org96d23d9" class="outline-4">
<h4 id="org96d23d9"><span class="section-number-4">6.1.2</span> <span class="todo INPROGRESS">INPROGRESS</span> Autoencoders:</h4>
<div class="outline-text-4" id="text-6-1-2">
</div>
<ol class="org-ol">
<li><a id="orgeb0290e"></a><span class="todo TODO">TODO</span> Adversarial Variational Bayes: Unifying Variational Autoencoders and Generative Adversarial Networks <sup><a id="fnr.3" class="footref" href="#fn.3">3</a></sup><br />
<div class="outline-text-5" id="text-6-1-2-1">
</div>

<ol class="org-ol">
<li><a id="org307cc2e"></a>Summary<br /></li>

<li><a id="orgc2f68b1"></a>Opinions<br /></li>

<li><a id="org7b97aa2"></a>Resources<br />
<div class="outline-text-6" id="text-6-1-2-1-3">
<p>
<a href="https://chrisorm.github.io/AVB-pyt.html">https://chrisorm.github.io/AVB-pyt.html</a>
</p>
</div>
</li>
</ol>
</li>

<li><a id="orga47bc67"></a><span class="todo TODO">TODO</span> Generalized Autoencoder: A Neural Network Framework for Dimensionality Reduction<sup><a id="fnr.4" class="footref" href="#fn.4">4</a></sup><br />
<div class="outline-text-5" id="text-6-1-2-2">
</div>

<ol class="org-ol">
<li><a id="org820cfe2"></a>Summary<br /></li>

<li><a id="orgf0c3cfc"></a>Opinions<br /></li>
</ol>
</li>

<li><a id="org8e391f3"></a><span class="todo TODO">TODO</span> Auto-Encoding Variational Bayes <sup><a id="fnr.5" class="footref" href="#fn.5">5</a></sup><br />
<div class="outline-text-5" id="text-6-1-2-3">
</div>

<ol class="org-ol">
<li><a id="org69496df"></a>Summary<br /></li>

<li><a id="org42ead3d"></a>Opinions<br /></li>
</ol>
</li>

<li><a id="orgc5e1654"></a><span class="todo TODO">TODO</span> InfoVAE: Balancing Learning and Inference in Variational Autoencoders <sup><a id="fnr.6" class="footref" href="#fn.6">6</a></sup><br />
<div class="outline-text-5" id="text-6-1-2-4">
</div>
<ol class="org-ol">
<li><a id="org096301b"></a>Summary<br /></li>
</ol>
</li>

<li><a id="orgb6a41b0"></a><span class="todo TODO">TODO</span> Adversarial Autoencoders <sup><a id="fnr.7" class="footref" href="#fn.7">7</a></sup><br />
<div class="outline-text-5" id="text-6-1-2-5">

<div id="org08222d8" class="figure">
<p><img src="resources/AAE.png" alt="AAE.png" width="600em" />
</p>
<p><span class="figure-number">Figure 1: </span>Adversarial Autoencoder structure</p>
</div>
</div>
<ol class="org-ol">
<li><a id="org0151696"></a>Summary<br /></li>
</ol>
</li>
</ol>
</div>

<div id="outline-container-org81c9f4c" class="outline-4">
<h4 id="org81c9f4c"><span class="section-number-4">6.1.3</span> <span class="todo INPROGRESS">INPROGRESS</span> Dimensionality reduction:</h4>
<div class="outline-text-4" id="text-6-1-3">
</div>
<ol class="org-ol">
<li><a id="orge4fcddb"></a><span class="done DONE">DONE</span> Auto-encoder based dimensionality reduction <sup><a id="fnr.2.100" class="footref" href="#fn.2">2</a></sup><br />
<div class="outline-text-5" id="text-6-1-3-1">
<p>
<b>Contributions</b>
</p>
<p class="verse">
We start from auto-encoder and focus on its ability to reduce<br />
the dimensionality, trying to understand the difference between<br />
auto-encoder and state-of-the-art dimensionality reduction<br />
methods. The results show that auto-encoder indeed learn<br />
something different from other methods.<br />
</p>

<p class="verse">
We preliminarily investigate the influence of the number of<br />
hidden layer nodes on the performance of auto-encoder on<br />
MNIST and Olivetti face datasets. The results reveal its possible<br />
relation with the intrinsic dimensionality.<br />
</p>
</div>
<ol class="org-ol">
<li><a id="org89b48dd"></a>Summary<br />
<div class="outline-text-6" id="text-6-1-3-1-1">
<p>
Shows comparison of Autoencoder and other dimensionality reduction
methods (e.g. PCA,LLE) Notable results: Autoencoder different than
other dimensionality reduction. Potentially detect repetitive
structures. Dimensionality of the <b>Latent space</b> is best when it
maches the intrinsic dimensionality of the dataset.
</p>
</div>
</li>

<li><a id="orgdd8eb56"></a>Opinions<br />
<div class="outline-text-6" id="text-6-1-3-1-2">
<p>
This clearly shows how Autoencoder can be essentially different and
more usefull than other dimensionality reduction methods. This
consolidate the choice of using autoencoders in the thesis.
</p>
</div>
</li>
</ol>
</li>

<li><a id="orgf658148"></a><span class="done DONE">DONE</span> Dimensionality Reduction of SDSS Spectra with Variational Autoencoders <sup><a id="fnr.8" class="footref" href="#fn.8">8</a></sup><br />
<div class="outline-text-5" id="text-6-1-3-2">
</div>

<ol class="org-ol">
<li><a id="org344e757"></a>Summary<br />
<div class="outline-text-6" id="text-6-1-3-2-1">
<p>
Show how AEs were already used in astrony for different dimensionality
reduction/classification task with success. Moreover, it aims to
address the limitation of PCA using VAE. Results show how on this
dataset (SDSS sloan digital sky survey) the autoencoder outperforms
PCA in particular with low dimension latent space(or component for
PCA)
They mainly use InfoVAE<sup><a id="fnr.6.100" class="footref" href="#fn.6">6</a></sup>,a variant of the VAE, focused on trying to
disentangle (e.i. force mapping different inputs to disjoint distribution ) the different latent space dimensions.
</p>
</div>
</li>
</ol>
</li>

<li><a id="org2ec06b3"></a><span class="done DISCARDED">DISCARDED</span> Dimensionality reduction for EEG-based sleep stage detection: comparison of autoencoders, principal component analysis and factor analysis <sup><a id="fnr.9" class="footref" href="#fn.9">9</a></sup><br />
<div class="outline-text-5" id="text-6-1-3-3">
<p>
It was <b>DISCARDED</b> because it contains too specific content and the
comparison between algorithms has multiple steps and variables which
are highly specific to the task. Therefore I do not think it should be
used.
</p>
</div>
</li>
<li><a id="org7bb4edd"></a><span class="done DONE">DONE</span> A deep adversarial variational autoencoder model for dimensionality reduction in single-cell RNA sequencing analysis <sup><a id="fnr.10" class="footref" href="#fn.10">10</a></sup><br />
<div class="outline-text-5" id="text-6-1-3-4">

<div id="org40c883f" class="figure">
<p><img src="resources/The-novel-architecture-of-an-Adversarial-Variational-AutoEncoder-with-Dual-Matching.png" alt="The-novel-architecture-of-an-Adversarial-Variational-AutoEncoder-with-Dual-Matching.png" width="600em" />
</p>
<p><span class="figure-number">Figure 2: </span>Adversarial Variational Autoencoder with dual matching</p>
</div>
</div>

<ol class="org-ol">
<li><a id="orgd3a5503"></a>Summary<br />
<div class="outline-text-6" id="text-6-1-3-4-1">
<p>
It introduces a novel Adversarial autoencoder architecture named
AVE-DM (Adversarial Variational autoencoder with dual matching )
The main difference between this new architecture and the prievious
proposed Adversarial autoencoders<sup><a id="fnr.7.100" class="footref" href="#fn.7">7</a></sup> is that it has 2
discriminator (hence the name dual matching).
Main Results: Shows how AVE-DM outperforms other state-of-the-art
methods such us PCA, UMAP (Uniform Manifold Approximation and
Projection),
t-SNE (T-distributed sochastic neighbor embedding ) etc.
Note: The interesting part of the data is that it have dropout event
(the reason for it is quite technical and specific to RNA
sequencing). This dropout event are zero expression measurament that
can be either biological or technical. This phenomenon result in poor
results for methods such us PCA or t-SNE.
</p>
</div>
</li>
</ol>
</li>
</ol>
</div>
<div id="outline-container-orgaaa0903" class="outline-4">
<h4 id="orgaaa0903"><span class="section-number-4">6.1.4</span> <span class="todo INPROGRESS">INPROGRESS</span> AE + RL:</h4>
<div class="outline-text-4" id="text-6-1-4">
</div>
<ol class="org-ol">
<li><a id="orgf60e362"></a><span class="done DONE">DONE</span> VARL: a variational autoencoder‑based reinforcement learning Framework for vehicle routing problems <sup><a id="fnr.11" class="footref" href="#fn.11">11</a></sup><br />
<div class="outline-text-5" id="text-6-1-4-1">
<p>
<b>Quotes</b>
</p>
<p class="verse">
It inherits the idea of variational inference to use a distribution to approximate the posterior distribution<sup><a id="fnr.5.100" class="footref" href="#fn.5">5</a></sup>. The<br />
diference is that VAE considers the posterior distribution<br />
of all data simultaneously and approximates each posterior<br />
distribution with distribution, minimizing KL divergence.<br />
</p>


<p class="verse">
It has many advantages,<br />
including fast training, stability, and so on, so it has a wide<br />
range of theoretical models and industry applications.<br />
</p>
</div>

<ol class="org-ol">
<li><a id="org785d34f"></a>Summary<br />
<div class="outline-text-6" id="text-6-1-4-1-1">
<p>
Introduces a new variational framework  for combinatorial optimization
(e.g. TSP). Introduces Variational inference and VAE. Propose VARL
(Variational autoencoder-based reinforcement learning) which exploits
variational inference ideas to learn efiiciently and effectively a
solution in a graph-based framework.
</p>
</div>
</li>

<li><a id="org99f12c2"></a>Opinions<br />
<div class="outline-text-6" id="text-6-1-4-1-2">
<p>
The main down side is that the VARL architecture seems to be quite
complex and specific for combinatorial optimization. That said, it
also shows how variational inference can be effectively used in
combination with reinforcement learning (in the paper REINFOCE was
specifically used.)
</p>
</div>
</li>
</ol>
</li>

<li><a id="orga1179df"></a><span class="todo TODO">TODO</span> Robot skill learning in latent space of a deep autoencoder neural network <sup><a id="fnr.12" class="footref" href="#fn.12">12</a></sup><br />
<div class="outline-text-5" id="text-6-1-4-2">
</div>

<ol class="org-ol">
<li><a id="org789b885"></a>Summary<br /></li>

<li><a id="orgcbdad45"></a>Opinions<br /></li>
</ol>
</li>

<li><a id="org711cc7c"></a><span class="todo TODO">TODO</span> AutoEncoder-based Safe Reinforcement Learning for Power Augmentation in a Lower-limb Exoskeleton <sup><a id="fnr.1.100" class="footref" href="#fn.1">1</a></sup><br />
<div class="outline-text-5" id="text-6-1-4-3">
</div>

<ol class="org-ol">
<li><a id="orge1c97c2"></a>Summary<br /></li>
<li><a id="org43a16fe"></a>Note<br />
<div class="outline-text-6" id="text-6-1-4-3-2">
<p>
data for AE training limited collection of real-world activities
use euclidean distance to train
generate data with GPR
</p>
</div>
</li>
</ol>
</li>

<li><a id="orgdadc7e6"></a><span class="todo TODO">TODO</span> The Dreaming Variational Autoencoder for Reinforcement Learning Environments <sup><a id="fnr.13" class="footref" href="#fn.13">13</a></sup><br />
<div class="outline-text-5" id="text-6-1-4-4">
</div>

<ol class="org-ol">
<li><a id="orgaa36396"></a>Summary<br /></li>

<li><a id="orge962d33"></a>Opinions<br /></li>
</ol>
</li>

<li><a id="org59af7ec"></a><span class="todo TODO">TODO</span> Deep Variational Reinforcement Learning for POMDPs <sup><a id="fnr.14" class="footref" href="#fn.14">14</a></sup><br />
<div class="outline-text-5" id="text-6-1-4-5">
</div>

<ol class="org-ol">
<li><a id="org0d9260b"></a>Summary<br /></li>

<li><a id="org1db4a06"></a>Opinions<br /></li>
</ol>
</li>

<li><a id="org4736e8f"></a><span class="todo TODO">TODO</span> On the use of Deep Autoencoders for Efficient Embedded Reinforcement Learning <sup><a id="fnr.15" class="footref" href="#fn.15">15</a></sup><br />
<div class="outline-text-5" id="text-6-1-4-6">
</div>

<ol class="org-ol">
<li><a id="orgf2d94ea"></a>Summary<br /></li>

<li><a id="org30a5ace"></a>Opinions<br /></li>
</ol>
</li>

<li><a id="org130166e"></a><span class="todo TODO">TODO</span> DARLA: Improving Zero-Shot Transfer in Reinforcement Learning <sup><a id="fnr.16" class="footref" href="#fn.16">16</a></sup><br />
<div class="outline-text-5" id="text-6-1-4-7">
</div>

<ol class="org-ol">
<li><a id="org052a49a"></a>Summary<br /></li>

<li><a id="org9a3ffe1"></a>Opinions<br /></li>

<li><a id="org6f2e6ec"></a>Resources<br />
<div class="outline-text-6" id="text-6-1-4-7-3">
<p>
<a href="http://proceedings.mlr.press/v70/higgins17a.html">http://proceedings.mlr.press/v70/higgins17a.html</a>
</p>
</div>
</li>
</ol>
</li>
</ol>
</div>
</div>



<div id="outline-container-org9d1f395" class="outline-3">
<h3 id="org9d1f395"><span class="section-number-3">6.2</span> Old ideas</h3>
<div class="outline-text-3" id="text-6-2">
</div>
<div id="outline-container-org960eb89" class="outline-4">
<h4 id="org960eb89"><span class="section-number-4">6.2.1</span> <span class="done DONE">DONE</span> Deep reinforcement learning for modeling human locomotion control in neuromechanical simulation <sup><a id="fnr.17" class="footref" href="#fn.17">17</a></sup></h4>
<div class="outline-text-4" id="text-6-2-1">
</div>

<ol class="org-ol">
<li><a id="org8407eb5"></a>Summary<br />
<div class="outline-text-5" id="text-6-2-1-1">
<p>
review paper, it introduces in general the topic. it illustrate
    previous methodology and then it moves on Deep Rl. It talks about
    Learn to Move competition and the different techniques used in
    that competition. Finally some future directions.
</p>
</div>
</li>

<li><a id="org3ef2074"></a>Opinions<br />
<div class="outline-text-5" id="text-6-2-1-2">
<p>
This paper is really interesting in particular the part about
Learn to Move and future directions.
</p>
</div>
</li>

<li><a id="org70603e2"></a>Ideas<br />
<div class="outline-text-5" id="text-6-2-1-3">
<p>
It suggest imitation learning and hierarchical learning
</p>
</div>
</li>
</ol>
</div>
</div>

<div id="outline-container-org5f960be" class="outline-3">
<h3 id="org5f960be"><span class="section-number-3">6.3</span> Old work</h3>
<div class="outline-text-3" id="text-6-3">
</div>
<div id="outline-container-org67505c2" class="outline-4">
<h4 id="org67505c2"><span class="section-number-4">6.3.1</span> Level ground walking for  healthy and transfemoral amputee models. Deep reinforcement learning with phasic policy gradient optimization <sup><a id="fnr.18" class="footref" href="#fn.18">18</a></sup></h4>
<div class="outline-text-4" id="text-6-3-1">
</div>
</div>

<div id="outline-container-org27677b0" class="outline-4">
<h4 id="org27677b0"><span class="section-number-4">6.3.2</span> Deep reinforcement learning for physics-based musculoskeletal model of a transfemoral amputee with a prothesis walking on uneven terrain <sup><a id="fnr.19" class="footref" href="#fn.19">19</a></sup></h4>
<div class="outline-text-4" id="text-6-3-2">
</div>
</div>

<div id="outline-container-org6d9ceb2" class="outline-4">
<h4 id="org6d9ceb2"><span class="section-number-4">6.3.3</span> Deep reinforcement learning for physics-based musculoskeletal simulations of healthy subjects and transfemoral protheses' users during normal walking <sup><a id="fnr.20" class="footref" href="#fn.20">20</a></sup></h4>
<div class="outline-text-4" id="text-6-3-3">
</div>
</div>

<div id="outline-container-org1b75d79" class="outline-4">
<h4 id="org1b75d79"><span class="section-number-4">6.3.4</span> Learning to walk: Phasic Policy Gradient for healthy and impaired musculoskeletal models <sup><a id="fnr.21" class="footref" href="#fn.21">21</a></sup></h4>
<div class="outline-text-4" id="text-6-3-4">
</div>
</div>

<div id="outline-container-orgb2a2119" class="outline-4">
<h4 id="orgb2a2119"><span class="section-number-4">6.3.5</span> Evaluating Deep Reinforcement Learning Algorithms for Physics-Based Musculoskeletal Transfemoral Model with a Prosthetic Leg Performing Ground-Level Walking <sup><a id="fnr.22" class="footref" href="#fn.22">22</a></sup></h4>
<div class="outline-text-4" id="text-6-3-5">
</div>
</div>

<div id="outline-container-org316b561" class="outline-4">
<h4 id="org316b561"><span class="section-number-4">6.3.6</span> Deep Reinforcement Learning for Physics-based Musculoskeletal Simulations of Transfemoral Prosthesis' Users during the Transition between Normal Walking and Stairs Ascending <sup><a id="fnr.23" class="footref" href="#fn.23">23</a></sup></h4>
<div class="outline-text-4" id="text-6-3-6">
</div>
</div>

<div id="outline-container-org5b303d6" class="outline-4">
<h4 id="org5b303d6"><span class="section-number-4">6.3.7</span> Testing For Generality Of A Proximal Policy Optimiser For Advanced Human Locomotion Beyond Walking <sup><a id="fnr.24" class="footref" href="#fn.24">24</a></sup></h4>
<div class="outline-text-4" id="text-6-3-7">
</div>
</div>
</div>
</div>

<div id="outline-container-orge70ab74" class="outline-2">
<h2 id="orge70ab74"><span class="section-number-2">7</span> Presentations</h2>
<div class="outline-text-2" id="text-7">
</div>
<div id="outline-container-orgdb24c8e" class="outline-3">
<h3 id="orgdb24c8e"><span class="section-number-3">7.1</span> First one</h3>
<div class="outline-text-3" id="text-7-1">
<iframe src="resources/init_pres.pdf" width="100%" style="height:50em" align="center"> </iframe>
</div>
</div>
</div>

<div id="outline-container-org8f3c7f9" class="outline-2">
<h2 id="org8f3c7f9"><span class="section-number-2">8</span> <span class="todo INPROGRESS">INPROGRESS</span> Code</h2>
<div class="outline-text-2" id="text-8">
<p>
Visit this file to see the current documentation
</p>
<div class="warning" id="orgcfb1844">
<p>
<b>WORK IN PROGRESS</b>  FIXME the documentation is in progress and it can be
 potentially not up to date
</p>

</div>
<p>
<a href="thesis/docs/build/html/index.html">thesis/docs/build/html/index.html</a>
</p>
</div>

<div id="outline-container-org8244f44" class="outline-3">
<h3 id="org8244f44"><span class="section-number-3">8.1</span> REPOS</h3>
<div class="outline-text-3" id="text-8-1">
<p>
<a href="https://github.com/vbotics/rug-opensim-rl">vbotics repo</a>
</p>

<p>
<a href="https://github.com/vimmoos/autoencoders">autoencoders code repo</a>
</p>

<p>
<a href="https://github.com/vimmoos/thesis">thesis repo</a>
</p>
</div>
</div>
</div>
<div id="outline-container-org9b94fb9" class="outline-2">
<h2 id="org9b94fb9"><span class="section-number-2">9</span> Contacts</h2>
<div class="outline-text-2" id="text-9">
</div>
<div id="outline-container-org5069c0c" class="outline-3">
<h3 id="org5069c0c"><span class="section-number-3">9.1</span> Massimiliano Falzari</h3>
<div class="outline-text-3" id="text-9-1">
<p>
m.falzari@student.rug.nl
</p>
</div>
</div>
<div id="outline-container-orge9569ff" class="outline-3">
<h3 id="orge9569ff"><span class="section-number-3">9.2</span> Professor</h3>
<div class="outline-text-3" id="text-9-2">
<ul class="org-ul">
<li>Raffealla carloni</li>
<li>SkypeID rafficar</li>
<li>BlueJeans <a href="https://bluejeans.com/821650990">https://bluejeans.com/821650990</a>  id number = 821650990</li>
</ul>
</div>
</div>
<div id="outline-container-org1ecc71a" class="outline-3">
<h3 id="org1ecc71a"><span class="section-number-3">9.3</span> Other Students</h3>
<div class="outline-text-3" id="text-9-3">
<ul class="org-ul">
<li>c.m.sreedhara@student.rug.nl</li>
<li>B.N.Ogum@student.rug.nl -&gt; Master student for dim red</li>
<li>Chadan</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgeef5044" class="outline-2">
<h2 id="orgeef5044"><span class="section-number-2">10</span> Todos</h2>
<div class="outline-text-2" id="text-10">
</div>
<div id="outline-container-org9a53233" class="outline-3">
<h3 id="org9a53233"><span class="section-number-3">10.1</span> Code</h3>
<div class="outline-text-3" id="text-10-1">
</div>
<div id="outline-container-org7469f4b" class="outline-4">
<h4 id="org7469f4b"><span class="section-number-4">10.1.1</span> <span class="done DONE">DONE</span> Vanilla Autoencoder</h4>
<div class="outline-text-4" id="text-10-1-1">
</div>
</div>
<div id="outline-container-orge1af2d1" class="outline-4">
<h4 id="orge1af2d1"><span class="section-number-4">10.1.2</span> <span class="done DONE">DONE</span> VAE</h4>
<div class="outline-text-4" id="text-10-1-2">
</div>
</div>
<div id="outline-container-org27b3771" class="outline-4">
<h4 id="org27b3771"><span class="section-number-4">10.1.3</span> <span class="done DONE">DONE</span> AVB</h4>
<div class="outline-text-4" id="text-10-1-3">
</div>
</div>
<div id="outline-container-org6723f19" class="outline-4">
<h4 id="org6723f19"><span class="section-number-4">10.1.4</span> <span class="done DONE">DONE</span> logging</h4>
<div class="outline-text-4" id="text-10-1-4">
</div>
</div>
<div id="outline-container-org399b7a5" class="outline-4">
<h4 id="org399b7a5"><span class="section-number-4">10.1.5</span> <span class="done DONE">DONE</span> tensorboard</h4>
<div class="outline-text-4" id="text-10-1-5">
</div>
</div>
<div id="outline-container-orgecb696d" class="outline-4">
<h4 id="orgecb696d"><span class="section-number-4">10.1.6</span> <span class="done DONE">DONE</span> data loader</h4>
<div class="outline-text-4" id="text-10-1-6">
</div>
</div>
<div id="outline-container-org54e2b72" class="outline-4">
<h4 id="org54e2b72"><span class="section-number-4">10.1.7</span> <span class="done DONE">DONE</span> cross validation</h4>
<div class="outline-text-4" id="text-10-1-7">
</div>
</div>
<div id="outline-container-orgfd48abd" class="outline-4">
<h4 id="orgfd48abd"><span class="section-number-4">10.1.8</span> <span class="done DONE">DONE</span> parse config</h4>
<div class="outline-text-4" id="text-10-1-8">
</div>
</div>
<div id="outline-container-orge81d7bf" class="outline-4">
<h4 id="orge81d7bf"><span class="section-number-4">10.1.9</span> <span class="done DONE">DONE</span> writer</h4>
<div class="outline-text-4" id="text-10-1-9">
</div>
<ol class="org-ol">
<li><a id="org2952d48"></a>Csv writer<br /></li>
<li><a id="orgb802354"></a>tensorboard writer<br /></li>
</ol>
</div>
<div id="outline-container-org4a856d7" class="outline-4">
<h4 id="org4a856d7"><span class="section-number-4">10.1.10</span> <span class="done DONE">DONE</span> validate with different loss</h4>
<div class="outline-text-4" id="text-10-1-10">
</div>
</div>
<div id="outline-container-org91e78d9" class="outline-4">
<h4 id="org91e78d9"><span class="section-number-4">10.1.11</span> <span class="done DONE">DONE</span> Create config parser module</h4>
<div class="outline-text-4" id="text-10-1-11">
</div>
</div>
<div id="outline-container-org09b18d1" class="outline-4">
<h4 id="org09b18d1"><span class="section-number-4">10.1.12</span> <span class="todo HOLD">HOLD</span> Dict -&gt; nametuple</h4>
</div>
<div id="outline-container-org1a911ce" class="outline-4">
<h4 id="org1a911ce"><span class="section-number-4">10.1.13</span> <span class="todo INPROGRESS">INPROGRESS</span> Graph module</h4>
</div>
<div id="outline-container-orgb3930a6" class="outline-4">
<h4 id="orgb3930a6"><span class="section-number-4">10.1.14</span> <span class="todo HOLD">HOLD</span> Collect Data from simulation</h4>
</div>
</div>
<div id="outline-container-org1736ec1" class="outline-3">
<h3 id="org1736ec1"><span class="section-number-3">10.2</span> Paper</h3>
<div class="outline-text-3" id="text-10-2">
</div>
<div id="outline-container-org36b5f03" class="outline-4">
<h4 id="org36b5f03"><span class="section-number-4">10.2.1</span> <span class="todo INPROGRESS">INPROGRESS</span> Review all papers</h4>
</div>
<div id="outline-container-orgd02bf28" class="outline-4">
<h4 id="orgd02bf28"><span class="section-number-4">10.2.2</span> <span class="todo HOLD">HOLD</span> Why we use autoencoders</h4>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><p class="footpara">
<a href="background/AutoEncoder-based_Safe_Reinforcement_Learning_for_Power_Augmentation_in_a_Lower-limb_Exoskeleton.pdf">background/AutoEncoder-based_Safe_Reinforcement_Learning_for_Power_Augmentation_in_a_Lower-limb_Exoskeleton.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2">2</a></sup> <div class="footpara"><p class="footpara">
<a href="background/Autoencoder_based_dimensionality_reduction.pdf">background/Autoencoder_based_dimensionality_reduction.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.3" class="footnum" href="#fnr.3">3</a></sup> <div class="footpara"><p class="footpara">
<a href="background/mescheder2017avb.pdf">background/mescheder2017avb.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.4" class="footnum" href="#fnr.4">4</a></sup> <div class="footpara"><p class="footpara">
<a href="background/Wang_Generalized_Autoencoder_A_2014_CVPR_paper.pdf">background/Wang_Generalized_Autoencoder_A_2014_CVPR_paper.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.5" class="footnum" href="#fnr.5">5</a></sup> <div class="footpara"><p class="footpara">
<a href="background/Auto-Encoding_Variational_Bayer.pdf">background/Auto-Encoding_Variational_Bayer.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.6" class="footnum" href="#fnr.6">6</a></sup> <div class="footpara"><p class="footpara">
<a href="background/infovae.pdf">background/infovae.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.7" class="footnum" href="#fnr.7">7</a></sup> <div class="footpara"><p class="footpara">
<a href="background/AdversarialAutoencoder.pdf">background/AdversarialAutoencoder.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.8" class="footnum" href="#fnr.8">8</a></sup> <div class="footpara"><p class="footpara">
<a href="background/dim_red_vae.pdf">background/dim_red_vae.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.9" class="footnum" href="#fnr.9">9</a></sup> <div class="footpara"><p class="footpara">
<a href="background/dim_red_comparison.pdf">background/dim_red_comparison.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.10" class="footnum" href="#fnr.10">10</a></sup> <div class="footpara"><p class="footpara">
<a href="background/VAE_dim_red_RNA_sequencing.pdf">background/VAE_dim_red_RNA_sequencing.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.11" class="footnum" href="#fnr.11">11</a></sup> <div class="footpara"><p class="footpara">
<a href="background/Wang2021_Article_VARLAVariationalAutoencoder-ba.pdf">background/Wang2021_Article_VARLAVariationalAutoencoder-ba.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.12" class="footnum" href="#fnr.12">12</a></sup> <div class="footpara"><p class="footpara">
<a href="background/robot_skill_learning_in_latent_space.pdf">background/robot_skill_learning_in_latent_space.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.13" class="footnum" href="#fnr.13">13</a></sup> <div class="footpara"><p class="footpara">
<a href="background/dreaming_autoencoder.pdf">background/dreaming_autoencoder.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.14" class="footnum" href="#fnr.14">14</a></sup> <div class="footpara"><p class="footpara">
<a href="background/dvrl.pdf">background/dvrl.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.15" class="footnum" href="#fnr.15">15</a></sup> <div class="footpara"><p class="footpara">
<a href="background/deep_ae+rl.pdf">background/deep_ae+rl.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.16" class="footnum" href="#fnr.16">16</a></sup> <div class="footpara"><p class="footpara">
<a href="background/DARLA.pdf">background/DARLA.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.17" class="footnum" href="#fnr.17">17</a></sup> <div class="footpara"><p class="footpara">
<a href="background/oldideas/Deep_reiforcement_learning_for_modeling_human_locomotion_in_neuromechanical_sim.pdf">background/oldideas/Deep_reiforcement_learning_for_modeling_human_locomotion_in_neuromechanical_sim.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.18" class="footnum" href="#fnr.18">18</a></sup> <div class="footpara"><p class="footpara">
<a href="background/oldwork/PPG.pdf">background/oldwork/PPG.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.19" class="footnum" href="#fnr.19">19</a></sup> <div class="footpara"><p class="footpara">
<a href="background/oldwork/Uneventerrain.pdf">background/oldwork/Uneventerrain.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.20" class="footnum" href="#fnr.20">20</a></sup> <div class="footpara"><p class="footpara">
<a href="background/oldwork/initThesis.pdf">background/oldwork/initThesis.pdf</a>
<a href="background/oldwork/initThesis2.pdf">background/oldwork/initThesis2.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.21" class="footnum" href="#fnr.21">21</a></sup> <div class="footpara"><p class="footpara">
<a href="background/oldwork/PPG_carloni.pdf">background/oldwork/PPG_carloni.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.22" class="footnum" href="#fnr.22">22</a></sup> <div class="footpara"><p class="footpara">
<a href="background/oldwork/shikha.pdf">background/oldwork/shikha.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.23" class="footnum" href="#fnr.23">23</a></sup> <div class="footpara"><p class="footpara">
<a href="background/oldwork/stairs.pdf">background/oldwork/stairs.pdf</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.24" class="footnum" href="#fnr.24">24</a></sup> <div class="footpara"><p class="footpara">
<a href="background/oldwork/generality.pdf">background/oldwork/generality.pdf</a>
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Massimiliano Falzari (s3459101)</p>
<p class="date">Created: 2022-01-27 Thu 10:19</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
